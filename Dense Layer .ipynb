{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5d4db86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hosei\\anaconda3\\envs\\tensorjoon\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9eb4c6c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>...</th>\n",
       "      <th>X170</th>\n",
       "      <th>X171</th>\n",
       "      <th>X172</th>\n",
       "      <th>X173</th>\n",
       "      <th>X174</th>\n",
       "      <th>X175</th>\n",
       "      <th>X176</th>\n",
       "      <th>X177</th>\n",
       "      <th>X178</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X21.V1.791</td>\n",
       "      <td>135</td>\n",
       "      <td>190</td>\n",
       "      <td>229</td>\n",
       "      <td>223</td>\n",
       "      <td>192</td>\n",
       "      <td>125</td>\n",
       "      <td>55</td>\n",
       "      <td>-9</td>\n",
       "      <td>-33</td>\n",
       "      <td>...</td>\n",
       "      <td>-17</td>\n",
       "      <td>-15</td>\n",
       "      <td>-31</td>\n",
       "      <td>-77</td>\n",
       "      <td>-103</td>\n",
       "      <td>-127</td>\n",
       "      <td>-116</td>\n",
       "      <td>-83</td>\n",
       "      <td>-51</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X15.V1.924</td>\n",
       "      <td>386</td>\n",
       "      <td>382</td>\n",
       "      <td>356</td>\n",
       "      <td>331</td>\n",
       "      <td>320</td>\n",
       "      <td>315</td>\n",
       "      <td>307</td>\n",
       "      <td>272</td>\n",
       "      <td>244</td>\n",
       "      <td>...</td>\n",
       "      <td>164</td>\n",
       "      <td>150</td>\n",
       "      <td>146</td>\n",
       "      <td>152</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>154</td>\n",
       "      <td>143</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X8.V1.1</td>\n",
       "      <td>-32</td>\n",
       "      <td>-39</td>\n",
       "      <td>-47</td>\n",
       "      <td>-37</td>\n",
       "      <td>-32</td>\n",
       "      <td>-36</td>\n",
       "      <td>-57</td>\n",
       "      <td>-73</td>\n",
       "      <td>-85</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>64</td>\n",
       "      <td>48</td>\n",
       "      <td>19</td>\n",
       "      <td>-12</td>\n",
       "      <td>-30</td>\n",
       "      <td>-35</td>\n",
       "      <td>-35</td>\n",
       "      <td>-36</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X16.V1.60</td>\n",
       "      <td>-105</td>\n",
       "      <td>-101</td>\n",
       "      <td>-96</td>\n",
       "      <td>-92</td>\n",
       "      <td>-89</td>\n",
       "      <td>-95</td>\n",
       "      <td>-102</td>\n",
       "      <td>-100</td>\n",
       "      <td>-87</td>\n",
       "      <td>...</td>\n",
       "      <td>-82</td>\n",
       "      <td>-81</td>\n",
       "      <td>-80</td>\n",
       "      <td>-77</td>\n",
       "      <td>-85</td>\n",
       "      <td>-77</td>\n",
       "      <td>-72</td>\n",
       "      <td>-69</td>\n",
       "      <td>-65</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X20.V1.54</td>\n",
       "      <td>-9</td>\n",
       "      <td>-65</td>\n",
       "      <td>-98</td>\n",
       "      <td>-102</td>\n",
       "      <td>-78</td>\n",
       "      <td>-48</td>\n",
       "      <td>-16</td>\n",
       "      <td>0</td>\n",
       "      <td>-21</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>-12</td>\n",
       "      <td>-32</td>\n",
       "      <td>-41</td>\n",
       "      <td>-65</td>\n",
       "      <td>-83</td>\n",
       "      <td>-89</td>\n",
       "      <td>-73</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 180 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed   X1   X2   X3   X4   X5   X6   X7   X8   X9  ...  X170  X171  \\\n",
       "0  X21.V1.791  135  190  229  223  192  125   55   -9  -33  ...   -17   -15   \n",
       "1  X15.V1.924  386  382  356  331  320  315  307  272  244  ...   164   150   \n",
       "2     X8.V1.1  -32  -39  -47  -37  -32  -36  -57  -73  -85  ...    57    64   \n",
       "3   X16.V1.60 -105 -101  -96  -92  -89  -95 -102 -100  -87  ...   -82   -81   \n",
       "4   X20.V1.54   -9  -65  -98 -102  -78  -48  -16    0  -21  ...     4     2   \n",
       "\n",
       "   X172  X173  X174  X175  X176  X177  X178  y  \n",
       "0   -31   -77  -103  -127  -116   -83   -51  4  \n",
       "1   146   152   157   156   154   143   129  1  \n",
       "2    48    19   -12   -30   -35   -35   -36  5  \n",
       "3   -80   -77   -85   -77   -72   -69   -65  5  \n",
       "4   -12   -32   -41   -65   -83   -89   -73  5  \n",
       "\n",
       "[5 rows x 180 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Epileptic Seizure Recognition.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c46e020d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11500 entries, 0 to 11499\n",
      "Columns: 180 entries, Unnamed to y\n",
      "dtypes: int64(179), object(1)\n",
      "memory usage: 15.8+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19e29a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11500, 178)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.iloc[:,1:-1].values\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91408646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11500, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data.iloc[:,-1:].values\n",
    "y[y>1] = 0\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8f3c880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8625, 178), (2875, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,shuffle=True)\n",
    "X_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f028a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denseBlock(dims,inp) :\n",
    "    x = tf.keras.layers.BatchNormalization() (inp)\n",
    "    x = tf.keras.layers.Dense(dims,activation=tf.keras.layers.LeakyReLU(0.2)) (x)\n",
    "    x = tf.keras.layers.Dropout(0.4) (x)\n",
    "    x = tf.keras.layers.Dense(dims,activation=tf.keras.layers.LeakyReLU(0.2)) (x)\n",
    "    x = tf.keras.layers.Dropout(0.4) (x)\n",
    "    x = tf.keras.layers.Dense(dims,activation=tf.keras.layers.LeakyReLU(0.2)) (x)\n",
    "    x = tf.keras.layers.Dropout(0.4) (x)\n",
    "    x = tf.keras.layers.Dense(178,activation=tf.keras.layers.LeakyReLU(0.2)) (x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be3d7b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hosei\\anaconda3\\envs\\tensorjoon\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inp = tf.keras.layers.Input(shape=(178,),name='input')\n",
    "x1 = denseBlock(256,inp)\n",
    "x2 = denseBlock(512,inp)\n",
    "x3 = denseBlock(1024,inp)\n",
    "x = tf.keras.layers.Concatenate()([x1,x2,x3])\n",
    "x = tf.keras.layers.Dense(128,activation=tf.keras.layers.LeakyReLU(0.2)) (x)\n",
    "out = tf.keras.layers.Dense(1,activation='sigmoid',name='output') (x)\n",
    "\n",
    "model = tf.keras.models.Model(inp,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5b28132",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "WARNING:tensorflow:From C:\\Users\\hosei\\anaconda3\\envs\\tensorjoon\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hosei\\anaconda3\\envs\\tensorjoon\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "54/54 [==============================] - 11s 70ms/step - loss: 0.6405 - accuracy: 0.7009 - val_loss: 0.4447 - val_accuracy: 0.9096\n",
      "Epoch 2/150\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.4078 - accuracy: 0.9036 - val_loss: 0.2262 - val_accuracy: 0.9507\n",
      "Epoch 3/150\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.2458 - accuracy: 0.9367 - val_loss: 0.1606 - val_accuracy: 0.9606\n",
      "Epoch 4/150\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.1807 - accuracy: 0.9507 - val_loss: 0.1454 - val_accuracy: 0.9641\n",
      "Epoch 5/150\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 0.1433 - accuracy: 0.9555 - val_loss: 0.1237 - val_accuracy: 0.9681\n",
      "Epoch 6/150\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.1331 - accuracy: 0.9612 - val_loss: 0.1022 - val_accuracy: 0.9733\n",
      "Epoch 7/150\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.1236 - accuracy: 0.9622 - val_loss: 0.1292 - val_accuracy: 0.9623\n",
      "Epoch 8/150\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.1094 - accuracy: 0.9654 - val_loss: 0.0953 - val_accuracy: 0.9751\n",
      "Epoch 9/150\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.1041 - accuracy: 0.9678 - val_loss: 0.0990 - val_accuracy: 0.9739\n",
      "Epoch 10/150\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 0.0972 - accuracy: 0.9664 - val_loss: 0.1048 - val_accuracy: 0.9728\n",
      "Epoch 11/150\n",
      "54/54 [==============================] - 3s 57ms/step - loss: 0.0897 - accuracy: 0.9712 - val_loss: 0.1015 - val_accuracy: 0.9728\n",
      "Epoch 12/150\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 0.0821 - accuracy: 0.9736 - val_loss: 0.1096 - val_accuracy: 0.9716\n",
      "Epoch 13/150\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 0.0800 - accuracy: 0.9741 - val_loss: 0.1220 - val_accuracy: 0.9664\n",
      "Epoch 14/150\n",
      "54/54 [==============================] - 3s 53ms/step - loss: 0.0805 - accuracy: 0.9739 - val_loss: 0.1114 - val_accuracy: 0.9699\n",
      "Epoch 15/150\n",
      "54/54 [==============================] - 3s 57ms/step - loss: 0.0799 - accuracy: 0.9754 - val_loss: 0.1133 - val_accuracy: 0.9704\n",
      "Epoch 16/150\n",
      "54/54 [==============================] - 3s 57ms/step - loss: 0.0850 - accuracy: 0.9717 - val_loss: 0.1208 - val_accuracy: 0.9675\n",
      "Epoch 17/150\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.0736 - accuracy: 0.9752 - val_loss: 0.1023 - val_accuracy: 0.9733\n",
      "Epoch 18/150\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.0706 - accuracy: 0.9754 - val_loss: 0.1052 - val_accuracy: 0.9728\n",
      "Epoch 19/150\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.0695 - accuracy: 0.9767 - val_loss: 0.1041 - val_accuracy: 0.9716\n",
      "Epoch 20/150\n",
      "54/54 [==============================] - 3s 57ms/step - loss: 0.0760 - accuracy: 0.9757 - val_loss: 0.0939 - val_accuracy: 0.9739\n",
      "Epoch 21/150\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.0633 - accuracy: 0.9783 - val_loss: 0.1078 - val_accuracy: 0.9751\n",
      "Epoch 22/150\n",
      "54/54 [==============================] - 3s 57ms/step - loss: 0.0672 - accuracy: 0.9765 - val_loss: 0.1072 - val_accuracy: 0.9722\n",
      "Epoch 23/150\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.0559 - accuracy: 0.9796 - val_loss: 0.0956 - val_accuracy: 0.9745\n",
      "Epoch 24/150\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.0614 - accuracy: 0.9774 - val_loss: 0.0971 - val_accuracy: 0.9733\n",
      "Epoch 25/150\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.0563 - accuracy: 0.9806 - val_loss: 0.0974 - val_accuracy: 0.9739\n",
      "Epoch 26/150\n",
      "54/54 [==============================] - 3s 57ms/step - loss: 0.0568 - accuracy: 0.9793 - val_loss: 0.0989 - val_accuracy: 0.9722\n",
      "Epoch 27/150\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.0585 - accuracy: 0.9783 - val_loss: 0.1092 - val_accuracy: 0.9704\n",
      "Epoch 28/150\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.0537 - accuracy: 0.9814 - val_loss: 0.1025 - val_accuracy: 0.9733\n",
      "Epoch 29/150\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.0591 - accuracy: 0.9783 - val_loss: 0.0942 - val_accuracy: 0.9728\n",
      "Epoch 30/150\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.0522 - accuracy: 0.9816 - val_loss: 0.0928 - val_accuracy: 0.9751\n",
      "Epoch 31/150\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.0516 - accuracy: 0.9822 - val_loss: 0.1093 - val_accuracy: 0.9733\n",
      "Epoch 32/150\n",
      "54/54 [==============================] - 3s 57ms/step - loss: 0.0476 - accuracy: 0.9820 - val_loss: 0.1195 - val_accuracy: 0.9699\n",
      "Epoch 33/150\n",
      "54/54 [==============================] - 3s 57ms/step - loss: 0.0494 - accuracy: 0.9836 - val_loss: 0.1037 - val_accuracy: 0.9722\n",
      "Epoch 34/150\n",
      "54/54 [==============================] - 3s 57ms/step - loss: 0.0495 - accuracy: 0.9833 - val_loss: 0.1287 - val_accuracy: 0.9693\n",
      "Epoch 35/150\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.0546 - accuracy: 0.9828 - val_loss: 0.1233 - val_accuracy: 0.9699\n",
      "Epoch 36/150\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.0485 - accuracy: 0.9830 - val_loss: 0.0955 - val_accuracy: 0.9757\n",
      "Epoch 37/150\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.0466 - accuracy: 0.9822 - val_loss: 0.1253 - val_accuracy: 0.9687\n",
      "Epoch 38/150\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.0500 - accuracy: 0.9822 - val_loss: 0.0915 - val_accuracy: 0.9751\n",
      "Epoch 39/150\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.0397 - accuracy: 0.9865 - val_loss: 0.0993 - val_accuracy: 0.9739\n",
      "Epoch 40/150\n",
      "54/54 [==============================] - 3s 57ms/step - loss: 0.0438 - accuracy: 0.9851 - val_loss: 0.0875 - val_accuracy: 0.9745\n",
      "Epoch 41/150\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.0519 - accuracy: 0.9809 - val_loss: 0.1126 - val_accuracy: 0.9728\n",
      "Epoch 42/150\n",
      "54/54 [==============================] - 4s 67ms/step - loss: 0.0427 - accuracy: 0.9838 - val_loss: 0.1077 - val_accuracy: 0.9716\n",
      "Epoch 43/150\n",
      "54/54 [==============================] - 4s 83ms/step - loss: 0.0414 - accuracy: 0.9845 - val_loss: 0.1127 - val_accuracy: 0.9722\n",
      "Epoch 44/150\n",
      "54/54 [==============================] - 3s 59ms/step - loss: 0.0417 - accuracy: 0.9848 - val_loss: 0.1075 - val_accuracy: 0.9739\n",
      "Epoch 45/150\n",
      "54/54 [==============================] - 5s 96ms/step - loss: 0.0463 - accuracy: 0.9832 - val_loss: 0.0937 - val_accuracy: 0.9722\n",
      "Epoch 46/150\n",
      "54/54 [==============================] - 5s 97ms/step - loss: 0.0451 - accuracy: 0.9817 - val_loss: 0.1173 - val_accuracy: 0.9716\n",
      "Epoch 47/150\n",
      "54/54 [==============================] - 5s 100ms/step - loss: 0.0412 - accuracy: 0.9851 - val_loss: 0.1200 - val_accuracy: 0.9728\n",
      "Epoch 48/150\n",
      "54/54 [==============================] - 5s 94ms/step - loss: 0.0405 - accuracy: 0.9848 - val_loss: 0.1128 - val_accuracy: 0.9710\n",
      "Epoch 49/150\n",
      "54/54 [==============================] - 5s 98ms/step - loss: 0.0421 - accuracy: 0.9864 - val_loss: 0.0940 - val_accuracy: 0.9739\n",
      "Epoch 50/150\n",
      "54/54 [==============================] - 5s 96ms/step - loss: 0.0372 - accuracy: 0.9874 - val_loss: 0.0941 - val_accuracy: 0.9728\n",
      "Epoch 51/150\n",
      "54/54 [==============================] - 5s 95ms/step - loss: 0.0409 - accuracy: 0.9846 - val_loss: 0.0965 - val_accuracy: 0.9739\n",
      "Epoch 52/150\n",
      "54/54 [==============================] - 5s 96ms/step - loss: 0.0329 - accuracy: 0.9886 - val_loss: 0.1080 - val_accuracy: 0.9757\n",
      "Epoch 53/150\n",
      "54/54 [==============================] - 5s 94ms/step - loss: 0.0396 - accuracy: 0.9871 - val_loss: 0.1052 - val_accuracy: 0.9739\n",
      "Epoch 54/150\n",
      "54/54 [==============================] - 5s 96ms/step - loss: 0.0366 - accuracy: 0.9881 - val_loss: 0.1091 - val_accuracy: 0.9716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/150\n",
      "54/54 [==============================] - 5s 97ms/step - loss: 0.0332 - accuracy: 0.9893 - val_loss: 0.1083 - val_accuracy: 0.9728\n",
      "Epoch 56/150\n",
      "54/54 [==============================] - 5s 96ms/step - loss: 0.0324 - accuracy: 0.9881 - val_loss: 0.0940 - val_accuracy: 0.9745\n",
      "Epoch 57/150\n",
      "54/54 [==============================] - 5s 95ms/step - loss: 0.0358 - accuracy: 0.9867 - val_loss: 0.1051 - val_accuracy: 0.9751\n",
      "Epoch 58/150\n",
      "54/54 [==============================] - 5s 96ms/step - loss: 0.0296 - accuracy: 0.9897 - val_loss: 0.1269 - val_accuracy: 0.9699\n",
      "Epoch 59/150\n",
      "54/54 [==============================] - 5s 95ms/step - loss: 0.0356 - accuracy: 0.9877 - val_loss: 0.0994 - val_accuracy: 0.9739\n",
      "Epoch 60/150\n",
      "54/54 [==============================] - 5s 97ms/step - loss: 0.0382 - accuracy: 0.9854 - val_loss: 0.1145 - val_accuracy: 0.9757\n",
      "Epoch 61/150\n",
      "54/54 [==============================] - 5s 98ms/step - loss: 0.0331 - accuracy: 0.9890 - val_loss: 0.1129 - val_accuracy: 0.9716\n",
      "Epoch 62/150\n",
      "54/54 [==============================] - 5s 96ms/step - loss: 0.0275 - accuracy: 0.9891 - val_loss: 0.1074 - val_accuracy: 0.9728\n",
      "Epoch 63/150\n",
      "54/54 [==============================] - 5s 96ms/step - loss: 0.0302 - accuracy: 0.9883 - val_loss: 0.1255 - val_accuracy: 0.9728\n",
      "Epoch 64/150\n",
      "54/54 [==============================] - 5s 99ms/step - loss: 0.0363 - accuracy: 0.9859 - val_loss: 0.1068 - val_accuracy: 0.9757\n",
      "Epoch 65/150\n",
      "54/54 [==============================] - 5s 97ms/step - loss: 0.0281 - accuracy: 0.9904 - val_loss: 0.1217 - val_accuracy: 0.9728\n",
      "Epoch 66/150\n",
      "54/54 [==============================] - 4s 73ms/step - loss: 0.0306 - accuracy: 0.9893 - val_loss: 0.0929 - val_accuracy: 0.9757\n",
      "Epoch 67/150\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 0.0380 - accuracy: 0.9854 - val_loss: 0.1388 - val_accuracy: 0.9670\n",
      "Epoch 68/150\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 0.0318 - accuracy: 0.9891 - val_loss: 0.1143 - val_accuracy: 0.9728\n",
      "Epoch 69/150\n",
      "54/54 [==============================] - 3s 53ms/step - loss: 0.0283 - accuracy: 0.9899 - val_loss: 0.1063 - val_accuracy: 0.9728\n",
      "Epoch 70/150\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.0313 - accuracy: 0.9904 - val_loss: 0.1159 - val_accuracy: 0.9739\n",
      "Epoch 71/150\n",
      "54/54 [==============================] - 3s 57ms/step - loss: 0.0280 - accuracy: 0.9890 - val_loss: 0.1231 - val_accuracy: 0.9751\n",
      "Epoch 72/150\n",
      "54/54 [==============================] - 3s 57ms/step - loss: 0.0282 - accuracy: 0.9897 - val_loss: 0.1064 - val_accuracy: 0.9762\n",
      "Epoch 73/150\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.0313 - accuracy: 0.9884 - val_loss: 0.1219 - val_accuracy: 0.9728\n",
      "Epoch 74/150\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.0268 - accuracy: 0.9904 - val_loss: 0.1212 - val_accuracy: 0.9728\n",
      "Epoch 75/150\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.0307 - accuracy: 0.9886 - val_loss: 0.1130 - val_accuracy: 0.9751\n",
      "Epoch 76/150\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.0253 - accuracy: 0.9909 - val_loss: 0.1044 - val_accuracy: 0.9762\n",
      "Epoch 77/150\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.0270 - accuracy: 0.9900 - val_loss: 0.1220 - val_accuracy: 0.9745\n",
      "Epoch 78/150\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.0237 - accuracy: 0.9917 - val_loss: 0.1139 - val_accuracy: 0.9757\n",
      "Epoch 79/150\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.0276 - accuracy: 0.9899 - val_loss: 0.1135 - val_accuracy: 0.9733\n",
      "Epoch 80/150\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.0288 - accuracy: 0.9901 - val_loss: 0.1284 - val_accuracy: 0.9728\n",
      "Epoch 81/150\n",
      "54/54 [==============================] - 3s 57ms/step - loss: 0.0261 - accuracy: 0.9907 - val_loss: 0.1057 - val_accuracy: 0.9768\n",
      "Epoch 82/150\n",
      "54/54 [==============================] - 3s 57ms/step - loss: 0.0230 - accuracy: 0.9925 - val_loss: 0.1431 - val_accuracy: 0.9710\n",
      "Epoch 83/150\n",
      "54/54 [==============================] - 3s 57ms/step - loss: 0.0230 - accuracy: 0.9903 - val_loss: 0.1518 - val_accuracy: 0.9699\n",
      "Epoch 84/150\n",
      "54/54 [==============================] - 3s 57ms/step - loss: 0.0246 - accuracy: 0.9916 - val_loss: 0.1399 - val_accuracy: 0.9739\n",
      "Epoch 85/150\n",
      "54/54 [==============================] - 3s 57ms/step - loss: 0.0209 - accuracy: 0.9928 - val_loss: 0.1278 - val_accuracy: 0.9733\n",
      "Epoch 86/150\n",
      "54/54 [==============================] - 3s 57ms/step - loss: 0.0226 - accuracy: 0.9909 - val_loss: 0.1159 - val_accuracy: 0.9739\n",
      "Epoch 87/150\n",
      "54/54 [==============================] - 3s 57ms/step - loss: 0.0204 - accuracy: 0.9936 - val_loss: 0.1214 - val_accuracy: 0.9733\n",
      "Epoch 88/150\n",
      "54/54 [==============================] - 3s 58ms/step - loss: 0.0263 - accuracy: 0.9907 - val_loss: 0.1120 - val_accuracy: 0.9745\n",
      "Epoch 89/150\n",
      "54/54 [==============================] - 3s 58ms/step - loss: 0.0203 - accuracy: 0.9919 - val_loss: 0.1175 - val_accuracy: 0.9745\n",
      "Epoch 90/150\n",
      "54/54 [==============================] - 3s 57ms/step - loss: 0.0250 - accuracy: 0.9897 - val_loss: 0.1444 - val_accuracy: 0.9722\n",
      "Epoch 91/150\n",
      "54/54 [==============================] - 3s 57ms/step - loss: 0.0215 - accuracy: 0.9916 - val_loss: 0.1301 - val_accuracy: 0.9733\n",
      "Epoch 92/150\n",
      "54/54 [==============================] - 3s 57ms/step - loss: 0.0262 - accuracy: 0.9897 - val_loss: 0.1129 - val_accuracy: 0.9716\n",
      "Epoch 93/150\n",
      "54/54 [==============================] - 3s 57ms/step - loss: 0.0213 - accuracy: 0.9913 - val_loss: 0.1432 - val_accuracy: 0.9710\n",
      "Epoch 94/150\n",
      "54/54 [==============================] - 3s 58ms/step - loss: 0.0211 - accuracy: 0.9929 - val_loss: 0.1239 - val_accuracy: 0.9716\n",
      "Epoch 95/150\n",
      "54/54 [==============================] - 3s 58ms/step - loss: 0.0193 - accuracy: 0.9930 - val_loss: 0.1305 - val_accuracy: 0.9751\n",
      "Epoch 96/150\n",
      "54/54 [==============================] - 3s 58ms/step - loss: 0.0263 - accuracy: 0.9903 - val_loss: 0.1163 - val_accuracy: 0.9757\n",
      "Epoch 97/150\n",
      "54/54 [==============================] - 3s 57ms/step - loss: 0.0193 - accuracy: 0.9929 - val_loss: 0.1313 - val_accuracy: 0.9728\n",
      "Epoch 98/150\n",
      "54/54 [==============================] - 4s 75ms/step - loss: 0.0254 - accuracy: 0.9896 - val_loss: 0.1087 - val_accuracy: 0.9745\n",
      "Epoch 99/150\n",
      "54/54 [==============================] - 4s 77ms/step - loss: 0.0258 - accuracy: 0.9914 - val_loss: 0.1137 - val_accuracy: 0.9733\n",
      "Epoch 100/150\n",
      "54/54 [==============================] - 4s 66ms/step - loss: 0.0197 - accuracy: 0.9932 - val_loss: 0.1220 - val_accuracy: 0.9733\n",
      "Epoch 101/150\n",
      "54/54 [==============================] - 5s 98ms/step - loss: 0.0160 - accuracy: 0.9946 - val_loss: 0.1245 - val_accuracy: 0.9745\n",
      "Epoch 102/150\n",
      "54/54 [==============================] - 5s 98ms/step - loss: 0.0190 - accuracy: 0.9935 - val_loss: 0.1282 - val_accuracy: 0.9710\n",
      "Epoch 103/150\n",
      "54/54 [==============================] - 5s 93ms/step - loss: 0.0175 - accuracy: 0.9936 - val_loss: 0.1220 - val_accuracy: 0.9728\n",
      "Epoch 104/150\n",
      "54/54 [==============================] - 5s 97ms/step - loss: 0.0222 - accuracy: 0.9923 - val_loss: 0.1206 - val_accuracy: 0.9728\n",
      "Epoch 105/150\n",
      "54/54 [==============================] - 5s 95ms/step - loss: 0.0247 - accuracy: 0.9913 - val_loss: 0.1358 - val_accuracy: 0.9739\n",
      "Epoch 106/150\n",
      "54/54 [==============================] - 5s 95ms/step - loss: 0.0202 - accuracy: 0.9907 - val_loss: 0.1303 - val_accuracy: 0.9739\n",
      "Epoch 107/150\n",
      "54/54 [==============================] - 5s 93ms/step - loss: 0.0227 - accuracy: 0.9932 - val_loss: 0.1115 - val_accuracy: 0.9762\n",
      "Epoch 108/150\n",
      "54/54 [==============================] - 5s 92ms/step - loss: 0.0158 - accuracy: 0.9942 - val_loss: 0.1325 - val_accuracy: 0.9722\n",
      "Epoch 109/150\n",
      "54/54 [==============================] - 5s 97ms/step - loss: 0.0163 - accuracy: 0.9933 - val_loss: 0.1129 - val_accuracy: 0.9768\n",
      "Epoch 110/150\n",
      "54/54 [==============================] - 5s 96ms/step - loss: 0.0178 - accuracy: 0.9935 - val_loss: 0.1247 - val_accuracy: 0.9733\n",
      "Epoch 111/150\n",
      "54/54 [==============================] - 5s 96ms/step - loss: 0.0132 - accuracy: 0.9954 - val_loss: 0.1461 - val_accuracy: 0.9722\n",
      "Epoch 112/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 5s 97ms/step - loss: 0.0208 - accuracy: 0.9928 - val_loss: 0.1241 - val_accuracy: 0.9757\n",
      "Epoch 113/150\n",
      "54/54 [==============================] - 5s 98ms/step - loss: 0.0205 - accuracy: 0.9930 - val_loss: 0.1282 - val_accuracy: 0.9704\n",
      "Epoch 114/150\n",
      "54/54 [==============================] - 5s 96ms/step - loss: 0.0176 - accuracy: 0.9935 - val_loss: 0.1269 - val_accuracy: 0.9716\n",
      "Epoch 115/150\n",
      "54/54 [==============================] - 5s 95ms/step - loss: 0.0220 - accuracy: 0.9906 - val_loss: 0.1204 - val_accuracy: 0.9762\n",
      "Epoch 116/150\n",
      "54/54 [==============================] - 5s 94ms/step - loss: 0.0189 - accuracy: 0.9925 - val_loss: 0.1272 - val_accuracy: 0.9728\n",
      "Epoch 117/150\n",
      "54/54 [==============================] - 5s 94ms/step - loss: 0.0171 - accuracy: 0.9935 - val_loss: 0.1292 - val_accuracy: 0.9728\n",
      "Epoch 118/150\n",
      "54/54 [==============================] - 5s 94ms/step - loss: 0.0167 - accuracy: 0.9933 - val_loss: 0.1313 - val_accuracy: 0.9722\n",
      "Epoch 119/150\n",
      "54/54 [==============================] - 5s 96ms/step - loss: 0.0191 - accuracy: 0.9922 - val_loss: 0.1322 - val_accuracy: 0.9739\n",
      "Epoch 120/150\n",
      "54/54 [==============================] - 5s 96ms/step - loss: 0.0187 - accuracy: 0.9938 - val_loss: 0.1273 - val_accuracy: 0.9745\n",
      "Epoch 121/150\n",
      "54/54 [==============================] - 5s 97ms/step - loss: 0.0176 - accuracy: 0.9939 - val_loss: 0.1251 - val_accuracy: 0.9751\n",
      "Epoch 122/150\n",
      "54/54 [==============================] - 5s 96ms/step - loss: 0.0153 - accuracy: 0.9939 - val_loss: 0.1423 - val_accuracy: 0.9722\n",
      "Epoch 123/150\n",
      "54/54 [==============================] - 5s 89ms/step - loss: 0.0169 - accuracy: 0.9946 - val_loss: 0.1289 - val_accuracy: 0.9722\n",
      "Epoch 124/150\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.0124 - accuracy: 0.9957 - val_loss: 0.1298 - val_accuracy: 0.9757\n",
      "Epoch 125/150\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.0132 - accuracy: 0.9949 - val_loss: 0.1377 - val_accuracy: 0.9739\n",
      "Epoch 126/150\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.0182 - accuracy: 0.9939 - val_loss: 0.1474 - val_accuracy: 0.9722\n",
      "Epoch 127/150\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.0117 - accuracy: 0.9959 - val_loss: 0.1378 - val_accuracy: 0.9739\n",
      "Epoch 128/150\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.0175 - accuracy: 0.9939 - val_loss: 0.1372 - val_accuracy: 0.9733\n",
      "Epoch 129/150\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.0173 - accuracy: 0.9938 - val_loss: 0.1331 - val_accuracy: 0.9762\n",
      "Epoch 130/150\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.0242 - accuracy: 0.9917 - val_loss: 0.1180 - val_accuracy: 0.9739\n",
      "Epoch 131/150\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 0.0133 - accuracy: 0.9955 - val_loss: 0.1391 - val_accuracy: 0.9739\n",
      "Epoch 132/150\n",
      "54/54 [==============================] - 3s 57ms/step - loss: 0.0143 - accuracy: 0.9949 - val_loss: 0.1142 - val_accuracy: 0.9757\n",
      "Epoch 133/150\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.0182 - accuracy: 0.9930 - val_loss: 0.1377 - val_accuracy: 0.9739\n",
      "Epoch 134/150\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.0123 - accuracy: 0.9951 - val_loss: 0.1313 - val_accuracy: 0.9728\n",
      "Epoch 135/150\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.0120 - accuracy: 0.9955 - val_loss: 0.1475 - val_accuracy: 0.9733\n",
      "Epoch 136/150\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.0199 - accuracy: 0.9933 - val_loss: 0.1291 - val_accuracy: 0.9716\n",
      "Epoch 137/150\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.0155 - accuracy: 0.9941 - val_loss: 0.1352 - val_accuracy: 0.9733\n",
      "Epoch 138/150\n",
      "54/54 [==============================] - 3s 58ms/step - loss: 0.0147 - accuracy: 0.9936 - val_loss: 0.1651 - val_accuracy: 0.9710\n",
      "Epoch 139/150\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.0109 - accuracy: 0.9964 - val_loss: 0.1497 - val_accuracy: 0.9722\n",
      "Epoch 140/150\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.0192 - accuracy: 0.9930 - val_loss: 0.2078 - val_accuracy: 0.9670\n",
      "Epoch 141/150\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.0112 - accuracy: 0.9955 - val_loss: 0.1541 - val_accuracy: 0.9728\n",
      "Epoch 142/150\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.0159 - accuracy: 0.9945 - val_loss: 0.1341 - val_accuracy: 0.9751\n",
      "Epoch 143/150\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.0123 - accuracy: 0.9955 - val_loss: 0.1423 - val_accuracy: 0.9722\n",
      "Epoch 144/150\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.0131 - accuracy: 0.9952 - val_loss: 0.1302 - val_accuracy: 0.9757\n",
      "Epoch 145/150\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.0125 - accuracy: 0.9951 - val_loss: 0.1404 - val_accuracy: 0.9733\n",
      "Epoch 146/150\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.0109 - accuracy: 0.9957 - val_loss: 0.1270 - val_accuracy: 0.9768\n",
      "Epoch 147/150\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.0151 - accuracy: 0.9949 - val_loss: 0.1350 - val_accuracy: 0.9739\n",
      "Epoch 148/150\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.0138 - accuracy: 0.9951 - val_loss: 0.1371 - val_accuracy: 0.9751\n",
      "Epoch 149/150\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.0134 - accuracy: 0.9954 - val_loss: 0.1548 - val_accuracy: 0.9739\n",
      "Epoch 150/150\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.0168 - accuracy: 0.9938 - val_loss: 0.1584 - val_accuracy: 0.9693\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2ee19b8af40>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train_scaled = sc.fit_transform(X_train)\n",
    "x_test_scaled = sc.transform(X_test)\n",
    "model.compile(loss='binary_crossentropy',optimizer=tf.keras.optimizers.Adam(1e-4),metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,epochs=150,batch_size=128,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9f003e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 1s 8ms/step - loss: 0.1663 - accuracy: 0.9638\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.16625168919563293, 0.963826060295105]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20ea98a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 1s 7ms/step\n",
      "Confusion Matrix:\n",
      "[[2317    0]\n",
      " [ 558    0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89      2317\n",
      "           1       0.00      0.00      0.00       558\n",
      "\n",
      "    accuracy                           0.81      2875\n",
      "   macro avg       0.40      0.50      0.45      2875\n",
      "weighted avg       0.65      0.81      0.72      2875\n",
      "\n",
      "Accuracy: 0.8059130434782609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hosei\\anaconda3\\envs\\tensorjoon\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\hosei\\anaconda3\\envs\\tensorjoon\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\hosei\\anaconda3\\envs\\tensorjoon\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test set\n",
    "y_pred = model.predict(x_test_scaled)\n",
    "\n",
    "# Convert predicted probabilities to binary predictions\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Calculate and print the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_binary)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Calculate and print classification report\n",
    "class_report = classification_report(y_test, y_pred_binary)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# Calculate and print accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Extract the number of seizure and non-seizure cases from the confusion matrix\n",
    "seizure_cases = conf_matrix[1, 1]  # True Positives\n",
    "non_seizure_cases = conf_matrix[0, 0]  # True Negatives\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5080a399",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorjoon",
   "language": "python",
   "name": "tensorjoon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
